
### JDK

java -version


### hadoop

# su - hduser

$ hadoop version

// SSH

master の id_rsa.pub を authorized_keys にコピー

master から ssh 確認：
$ ssh (IP)


$ pwd
/opt/hadoop/etc/hadoop

hadoop-env.sh
yarn-env.sh を確認

// core-site.xml

IP address に変更する

    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:8020</value>
    </property>

// yarn-site.xml
  <property>
    <name>yarn.resourcemanager.hostname</name>
    <value>localhost</value>
  </property>


// slaves
master の slaves に追加
(master の daemon を止めた後の方が良い。)


### HDFS

($ hdfs namenode -format)

master で daemon を止めた後、hdfs を再起動：

$ stop-hbase.sh
$ ./hadoop/sbin/stop-yarn.sh
$ ./hadoop/sbin/stop-dfs.sh

$ ./sbin/start-dfs.sh

$ hdfs dfs -ls /


### YARN

$ ./start-yarn.sh

$ hadoop jar hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar pi 4 100


### SPARK

/opt/spark/conf/log4j.properties の INFO => WARN


### HBASE

// hbase-env.sh
確認

// hbase-site.xml
２箇所変更

   <property>
      <name>hbase.rootdir</name>
      <value>hdfs://localhost:8020/hbase</value>
   </property>
   <property>
      <name>hbase.cluster.distributed</name>
      <value>true</value>
   </property>
   <property>
      <name>dfs.replication</name>
      <value>1</value>
   </property>
   <property>
      <name>hbase.zookeeper.quorum</name>
      <value>localhost</value>
   </property>

// regionservers

変更

%%
$ start-hbase.sh
