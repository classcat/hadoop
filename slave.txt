
### 準備

# apt-get update && apt-get -y upgrade && apt-get -y dist-upgrade
# sync && reboot
# apt-get install git

# git clone https://github.com/classcat/hadoop.git


### JDK

再ログインして以下を確認：

java -version


### hadoop

hadoop.conf の MASTER_NODE_IP を設定してからスクリプト実効

# su - hduser

// SSH

最初に master の id_rsa.pub を authorized_keys にコピー

master から ssh 確認：
$ ssh (IP)


* 設定ファイルを確認：
hadoop-env.sh
yarn-env.sh
core-site.xml
yarn-site.xml

$ hadoop version


// slaves
master の slaves ファイルに追加


*** ここで他の slave 作業へ、あるいは slave がなければ master へ ***


### HDFS

($ hdfs namenode -format)

master で daemon を止めた後、hdfs を再起動：

$ stop-hbase.sh
$ ./hadoop/sbin/stop-yarn.sh
$ ./hadoop/sbin/stop-dfs.sh

$ ./sbin/start-dfs.sh

$ hdfs dfs -ls /


### YARN

$ ./start-yarn.sh

$ hadoop jar hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar pi 4 100


### SPARK

/opt/spark/conf/log4j.properties の INFO => WARN


### HBASE

// hbase-env.sh
確認

// hbase-site.xml
２箇所変更

   <property>
      <name>hbase.rootdir</name>
      <value>hdfs://localhost:8020/hbase</value>
   </property>
   <property>
      <name>hbase.cluster.distributed</name>
      <value>true</value>
   </property>
   <property>
      <name>dfs.replication</name>
      <value>1</value>
   </property>
   <property>
      <name>hbase.zookeeper.quorum</name>
      <value>localhost</value>
   </property>

// regionservers

変更

%%
$ start-hbase.sh
